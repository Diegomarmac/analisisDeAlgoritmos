{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b66de97",
   "metadata": {},
   "source": [
    "## 3.1-1\n",
    "Tomamos $f(n)$ y $g(n)$ como funciones asintoticas y no negativas, así pues n puede tomar cualquier valor dentro de cada función y por ende, n es asu vez, también no negativo, es decir $n >= 0$ entonces, al poder ser cualquier valor dentro de $f$ y de $g$, podemos asumir que $n = max$ y tomemos $c_1 = 0.5$ & $c_2 = 1$ de esta foirma podemos decir que:  \n",
    "\n",
    "$0 <= 0.5(f(n) + g(n))$ y como n tiende al max, entonces podemos hacer la siguiente igualdad:  \n",
    "\n",
    "$0 <= 0.5(f(n) + g(n)) <= 0.5max(f(n),g(n)) + max(f(n),g(n))$   \n",
    "\n",
    "que desarrollando tenemos:  \n",
    "\n",
    "$max(f(n),g(n)) <= max(f(n),g(n)) + min(f(n),g(n)) = (f(n) + g(n))$ y listo !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258479a7",
   "metadata": {},
   "source": [
    "## 3.1-2\n",
    "Hagamos $c = 2^b$ y $n_0 >= 2a$ entonces para todo $n >= n_0$ tenemos que  \n",
    "$(n + a)^b <= (2n)^b$ y notamos que $(2n)^b$ puede reescribirse como $cn^b$ entonces nos queda $(n + a)^b = \\theta (n^b)$  \n",
    "\n",
    "Ahora supongamos $n_0 >= \\frac{-a}{1 - 1/2^{1/b}}$ y $c = \\frac{1}{2}$. Así la desigualdad nos queda:  \n",
    "\n",
    "$n >= n_0 \\frac{-a}{1-1/2^{1/b}}$\n",
    "\n",
    "El _teorema 3.1_ del libro nos indica que $(n+a)^b = \\theta(n)^b$. Para que esto se cumpla deben de cumplirse en relación __si y solo si__ los siguientes supuestos:\n",
    "- $n - \\frac{n}{2^{1/b}} > = -a$\n",
    "- $n +a > = (\\frac{1}{2})^{a/b} $\n",
    "- $(n+a)^b >= cn^b$\n",
    "Si estos se cumplen en relación __si y solo si__ entonces:  \n",
    "\n",
    "$(a+n)^b = \\theta(n^b)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fee5421",
   "metadata": {},
   "source": [
    "## 3.1-3\n",
    "Existen muchos algoritmos actualmente que pueden resolver problemas complejos en poco tiempo, aún tratandose de una cantidad elevada de _inputs_ y eso es lo importante para problemas acutales, el poder trabajr con millones de datos en el tiempo más corto posible, si usaramos un algorithmo de tiempo $\\theta(n^2)$ para poder realizar operaciones con miles de datos solamente, podría tomar un par de días, por lo que para los problemas y situaciones de hoy en día, trabajr con un tiempo tan lento se vuelve _inutil_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fface6a1",
   "metadata": {},
   "source": [
    "## 3.1-4\n",
    "Por propiedades de las potencias podemos reescribir $2^{n+1}$ como $2(2^n)$ para todo n positivo, así pues $n+1$ queda dentro del rango de n, por lo que se puede reescribir simplemente como n, por lo tanto $2^{n+1} = \\theta(2^n)$.  \n",
    "\n",
    "Ahora, si existe un $n_0$ y un $c$ tal que $n >= n_0$ esto implica que $2^{2n} <= c2^{n}$, así pues tenemos que $2^n <= c$ para $n >= n_0$ lo que no tiene sentido, es decir, estamos tratando de indicar que $2^{2n} = \\theta(2^n)$ pero vemos que al desarrollarlo se llega a conclusiones que no tienen sentido, por lo cual no es posible que $2^{2n} = \\theta(2^n)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57bb56de",
   "metadata": {},
   "source": [
    "## 3.1-6 \n",
    "Supongamos que el tiempo de ejecución es $\\theta(g(n))$. y tomando que para dos funciones $f(n)$ & $g(n)$ tenemos que $f(n) = \\theta(g(n))$ __si y solo si__ $f(n) = O(g(n))$ y por lo tanto $f(n) \\Omega(g(n))$, así pues el tiempo de ejecución puede ser escrito como $O(g(n))$ lo cual implica para cualquier input de tamaño $n >= n_0$ el tiempo de ejecución tiene un límite superior en $c_1g(n)$ para algún $c_1$, aquí entra también el denominado _worst case_ .  \n",
    "\n",
    "Siguiendo el teorema descrito al inicio de este punto, tenemos además que el tiempo de ejecución puede ser escrito como $\\Omega(g(n))$ lo que queda para cualquier $n >= n_0$  y como la notación OMega va en limites inferiores, entonces tenemos que ese limite inferior en $c_2g(n)$ para algún $c_2$, en este punto tenemos el _best case_.  \n",
    "\n",
    "Por lo tanto podemos decir que el peor caso está definido por $O(g(n))$ mientras que el mejor caso está definido por $\\Omega(g(n))$  así pues, y usando el teorema definido al inicio de este punto, podemos dar el tiempo de ejecución $\\theta(g(n))$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d778700",
   "metadata": {},
   "source": [
    "## 3.1-7\n",
    "Definimos $f(n) \\in o(g(n)) \\cap \\omega(g(n))$ por lo que tendríamos la siguiente contradicción:  \n",
    "\n",
    "$O = \\lim_{x \\to \\infty} \\frac{f(n)}{g(n)} = \\infty$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f48582",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.2",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
